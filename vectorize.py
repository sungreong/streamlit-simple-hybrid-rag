import os
import json
import pickle
import numpy as np
import re
from kiwipiepy import Kiwi
from rank_bm25 import BM25Okapi
from sentence_transformers import SentenceTransformer
import faiss

# 1. ë¬¸ì„œ ë¡œë“œ ë° ì „ì²˜ë¦¬
def chunk_markdown_hierarchical(text, filename):
    """
    ë§ˆí¬ë‹¤ìš´ íŒŒì¼ì„ ê³„ì¸µ êµ¬ì¡°ë¥¼ ìœ ì§€í•˜ë©´ì„œ ì²­í¬ë¡œ ë¶„ë¦¬í•©ë‹ˆë‹¤.
    ê° ì²­í¬ëŠ” ìƒìœ„ í—¤ë”ë¥¼ í¬í•¨í•˜ì—¬ ì»¨í…ìŠ¤íŠ¸ë¥¼ ìœ ì§€í•©ë‹ˆë‹¤.
    """
    lines = text.split('\n')
    chunks = []
    current_headers = {1: None, 2: None, 3: None}  # H1, H2, H3 ì¶”ì 
    current_content = []
    
    for line in lines:
        # í—¤ë” ê°ì§€ (# , ## , ###)
        header_match = re.match(r'^(#{1,3})\s+(.+)$', line)
        
        if header_match:
            # ì´ì „ ì²­í¬ ì €ìž¥
            if current_content:
                chunk_text = '\n'.join(current_content).strip()
                if chunk_text:
                    chunks.append(chunk_text)
                current_content = []
            
            # í—¤ë” ë ˆë²¨ íŒŒì•…
            level = len(header_match.group(1))
            header_text = header_match.group(2).strip()
            
            # í˜„ìž¬ ë ˆë²¨ ì—…ë°ì´íŠ¸
            current_headers[level] = line
            # í•˜ìœ„ ë ˆë²¨ ì´ˆê¸°í™”
            for i in range(level + 1, 4):
                current_headers[i] = None
            
            # ìƒìœ„ í—¤ë”ë“¤ì„ í¬í•¨í•˜ì—¬ ìƒˆ ì²­í¬ ì‹œìž‘
            for i in range(1, 4):
                if current_headers[i]:
                    current_content.append(current_headers[i])
        else:
            # ì¼ë°˜ ì½˜í…ì¸ 
            if line.strip():
                current_content.append(line)
    
    # ë§ˆì§€ë§‰ ì²­í¬ ì €ìž¥
    if current_content:
        chunk_text = '\n'.join(current_content).strip()
        if chunk_text:
            chunks.append(chunk_text)
    
    return chunks

def chunk_simple(text):
    """
    ê°„ë‹¨í•œ ì¤„ë°”ê¿ˆ ê¸°ë°˜ ì²­í‚¹ (ê¸°ì¡´ ë°©ì‹)
    """
    return [c.strip() for c in text.split('\n') if c.strip()]

def load_documents(data_dir, use_hierarchical=True):
    """
    ë¬¸ì„œë¥¼ ë¡œë“œí•˜ê³  ì²­í‚¹í•©ë‹ˆë‹¤.
    
    Args:
        data_dir: ë°ì´í„° ë””ë ‰í† ë¦¬ ê²½ë¡œ
        use_hierarchical: Trueë©´ ë§ˆí¬ë‹¤ìš´ ê³„ì¸µ êµ¬ì¡° ìœ ì§€, Falseë©´ ë‹¨ìˆœ ì²­í‚¹
    """
    documents = []
    files = [f for f in os.listdir(data_dir) if f.endswith((".txt", ".md"))]
    
    print(f"   ë°œê²¬ëœ íŒŒì¼: {len(files)}ê°œ")
    print()
    
    for idx, filename in enumerate(files, 1):
        path = os.path.join(data_dir, filename)
        
        # íŒŒì¼ ì²˜ë¦¬ ì‹œìž‘ í‘œì‹œ
        print(f"   [{idx}/{len(files)}] ðŸ“„ {filename} ì²˜ë¦¬ ì¤‘...", end=" ")
        
        with open(path, "r", encoding="utf-8") as f:
            text = f.read()
            
            # ì²­í‚¹ ì „ëžµ ì„ íƒ
            if use_hierarchical and filename.endswith(".md"):
                chunks = chunk_markdown_hierarchical(text, filename)
                strategy = "ê³„ì¸µêµ¬ì¡°"
            else:
                chunks = chunk_simple(text)
                strategy = "ë‹¨ìˆœ"
            
            # ë¬¸ì„œ ì—”íŠ¸ë¦¬ ìƒì„±
            for i, chunk in enumerate(chunks):
                doc_entry = {
                    "doc_id": filename,
                    "chunk_id": f"{filename}::chunk::{i}",
                    "text": chunk,
                    "metadata": {
                        "source": path,
                        "index": i,
                        "total_chunks": len(chunks),
                        "prev_chunk_id": f"{filename}::chunk::{i-1}" if i > 0 else None,
                        "next_chunk_id": f"{filename}::chunk::{i+1}" if i < len(chunks) - 1 else None,
                        "chunking_strategy": "hierarchical" if (use_hierarchical and filename.endswith(".md")) else "simple"
                    }
                }
                documents.append(doc_entry)
            
            # ì²˜ë¦¬ ì™„ë£Œ í‘œì‹œ
            print(f"âœ… {len(chunks)}ê°œ ì²­í¬ ìƒì„± ({strategy})")
    
    print()
    return documents

# 2. BM25 ì¸ë±ì‹± (ëª…ì‚¬/ë™ì‚¬ ìœ„ì£¼ í† í°í™”)
def build_bm25(documents):
    kiwi = Kiwi()
    tokenized_corpus = []
    for doc in documents:
        # í˜•íƒœì†Œ ë¶„ì„ í›„ ëª…ì‚¬(N), ë™ì‚¬(V), í˜•ìš©ì‚¬(J) ì¶”ì¶œ
        tokens = [t.form for t in kiwi.tokenize(doc['text']) if t.tag.startswith(('N', 'V', 'J'))]
        tokenized_corpus.append(tokens)
    
    bm25 = BM25Okapi(tokenized_corpus)
    return bm25, tokenized_corpus

# 3. Semantic ì¸ë±ì‹± (ë²¡í„°ë¼ì´ì§•)
def build_faiss(documents):
    model = SentenceTransformer('jhgan/ko-sroberta-multitask') # í•œêµ­ì–´ ì„±ëŠ¥ì´ ì¢‹ì€ ëª¨ë¸
    texts = [doc['text'] for doc in documents]
    embeddings = model.encode(texts)
    
    # Cosine Similarityë¥¼ ìœ„í•´ L2 ì •ê·œí™” í›„ Inner Product ì‚¬ìš©
    dim = embeddings.shape[1]
    index = faiss.IndexFlatIP(dim)
    faiss.normalize_L2(embeddings)
    index.add(embeddings)
    
    return index, model

def main():
    data_dir = "./data"
    output_dir = "./index_output"
    os.makedirs(output_dir, exist_ok=True)

    # ì²­í‚¹ ì „ëžµ ì„ íƒ (ê¸°ë³¸ê°’: hierarchical=True)
    use_hierarchical = True  # Falseë¡œ ë³€ê²½í•˜ë©´ ê¸°ì¡´ ë‹¨ìˆœ ì²­í‚¹ ì‚¬ìš©
    
    print("ðŸš€ ë¬¸ì„œ ë¡œë“œ ì¤‘...")
    print(f"   ì²­í‚¹ ì „ëžµ: {'ê³„ì¸µ êµ¬ì¡° ìœ ì§€ (ë§ˆí¬ë‹¤ìš´)' if use_hierarchical else 'ë‹¨ìˆœ ì¤„ë°”ê¿ˆ'}")
    docs = load_documents(data_dir, use_hierarchical=use_hierarchical)
    
    print("ðŸš€ BM25 ì¸ë±ìŠ¤ ìƒì„± ì¤‘...")
    bm25, tokenized_corpus = build_bm25(docs)
    
    print("ðŸš€ Semantic (FAISS) ì¸ë±ìŠ¤ ìƒì„± ì¤‘...")
    faiss_index, model = build_faiss(docs)

    # ì €ìž¥
    print("ðŸ“‚ ì¸ë±ìŠ¤ ì €ìž¥ ì¤‘...")
    # 1. ë©”íƒ€ë°ì´í„° ë° ë¬¸ì„œ ì›ë¬¸
    with open(os.path.join(output_dir, "metadata.json"), "w", encoding="utf-8") as f:
        json.dump(docs, f, ensure_ascii=False, indent=2)
    
    # 2. BM25 (Object ìžì²´ ì €ìž¥ ë˜ëŠ” í† í° ì €ìž¥)
    with open(os.path.join(output_dir, "bm25.pkl"), "wb") as f:
        pickle.dump(bm25, f)
    
    # 3. FAISS Index
    faiss.write_index(faiss_index, os.path.join(output_dir, "index.faiss"))

    print(f"âœ… ì¸ë±ì‹± ì™„ë£Œ! (ë¬¸ì„œ ìˆ˜: {len(docs)})") 
    print(f"ðŸ“ ì €ìž¥ ìœ„ì¹˜: {output_dir}")
    
    # ì²­í‚¹ ì „ëžµë³„ í†µê³„
    hierarchical_count = sum(1 for d in docs if d['metadata'].get('chunking_strategy') == 'hierarchical')
    simple_count = len(docs) - hierarchical_count
    print(f"ðŸ“Š ì²­í‚¹ í†µê³„: ê³„ì¸µêµ¬ì¡°={hierarchical_count}, ë‹¨ìˆœ={simple_count}")

if __name__ == "__main__":
    main()
